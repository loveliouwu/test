
驱动程序可以通过 request_irq() 函数注册一个中断处理程序 在文件<linux/interrupt.h>中声明
	int request_irq(
					unsigned int irq,			//中断号
					irq_handler_t handler,		//指针，指向处理这个中断的实际中断处理程序
					unsigned long flags,		//中断处理标志
					const char * name,			//设备的ASCII文本表示
					void *dev					//用于共享中断线
					)
	中断处理标志：
		IRQF_DISABLED
		IRQF_SAMPLE_RANDOM
		IRQF_TIMER
		IRQF_SHARED

	request_irq()成功执行会返回0，如果返回非0值就表示有错误发生，这种情况下，指定的中断处理程序不会被注册
		最常见的错误是 -EBUSY，它表示给定的中断线已经在使用
	
	注意：request_irq()函数可能会睡眠，因此不能再不允许阻塞的代码中调用该函数
	
卸载驱动程序时，需要注销相应的中断处理程序，并释放中断线
		void free_irq(unsigned int irq , void * dev)
		

中断处理例程：
	static irqreturn_t intr_handler(int irq , void * dev)
	
	返回值是一个特殊类型： irqreturn_t {IRQ_NONE , IRQ_HANDLED}
	当检测到的中断对应的设备并不是在注册处理函数期间指定的产生源时，返回IRQ_NONE；
	当中断处理程序被正确调用，且确实是它所对应的设备产生了中断时，返回IRQ_HANDLED


共享的中断处理程序 request_irq（）的参数flags必须设置IRQF_SHARED标志
	dev参数必须唯一
	中断处理程序必须能够区分它的设备是否真的产生了中断
	
	
禁止和激活中断：
	local_irq_disable()
	local_irq_enable()
	在单处理器不可抢占系统中，使用local_irq_enable 和 local_irq_disable 是消除异步并发源的有效方式
	local_irq_enable	宏用来打开本地处理器的中断， local_irq_disable	则正好相反
	这两个宏调用 raw_local_irq_enable()和raw_local_irq_disable()  
	在单处理器不可抢占系统中，如果某段代码要访问共享资源，那么在进入临界区前使用local_irq_disable来关闭中断
	这样在临界区中可保证不会出现异步并发源，访问完共享资源在出临界区时，在调用local_irq_enable来启动中断
	
	他们还有一种变体： local_irq_save   local_irq_restore
	区别是local_irq_save会在关闭中断前，将处理器当前的标志位保存在一个unsigned long flags中  在调用local_irq_restore时候，
	再将保存的flags恢复到FLAGS寄存器中，这样做的目的是防止在一个中断关闭的观景中因为调用local_irq_disable与local_irq_enable将之前的中断响应状态破坏掉

下半部接口：
		软中断、tasklet
	有三种机制可以用来实现将工作推后执行：
		软中断、tasklet、工作队列

软中断：
	它是一组静态定义的下半部接口，
	软中断是在编译期间静态分配的，软中断由softirq_action 结构表示 定义在<linux/interrupt.h>中
	kernel/softirq.c 中定义了一个包含32个该结构体的数组
	static struct softirq_action softirq_vec[NR_SOFTIRQS];
	每个被注册的软中断都占据该数组的一项，因此最多可能有32个软中断
	软中断处理程序action：
		void softirq_handler（struct softirq_action * ）
		当内核运行一个软中断处理程序时，它就会执行这个action函数，其唯一的参数为指向相应softirq_action结构体的指针，
			例如：如果my_softirq指向softirq_vec数组的某项，那么内核就会用以下方式调用软中断处理程序中的函数：
			my_softirq->action(my_softirq);
		唤起软中断后，软中断都要在do_softirq()中执行，如果有待处理的软中断，do_softirq()会循环遍历每一个，调用它们的处理程序
			{
				1. 用局部变量spending保存local_sofairq_spending（）宏的返回值，它是待处理的软中断的32位位图--如果第n位被设置为1
				那么第n位对应类型的软中断等待处理
				2.现在待处理的软中断位图已经被保存,可以将实际的软中断位图清零了（实际执行此步骤时需要禁止本地中断）
				3.将指针h指向softirq_vec的第一项
				4.如果spending的第一位被置为1，则h->action(h)被调用
				5.指针加1，所以现在指向softirq_vec数组的第二项
				6.位掩码spending右移一位，这样会丢弃第一位
				7.现在h指向数组的第二项，pending位掩码的第二位也到了第一项，重复步骤4
				8.一直重复直到pending变为0，表明已经没有待处理的软中断了，因为pending最多只可能设置32位，循环最多执行32次
			}
	使用软中断：
		1.	分配索引，通过在interrup.h中定义的一个枚举类型来静态地声明软中断，内核用这些从0开始的索引来表示一种相对优先级
			一般是HI_SOFTIRQ作为第一项，而RCU_SOFTIRQ作为最后一项，新项可能插在BLOCK_SOFTIRQ和TASKLET_SOFTIRQ之间
		2.	注册处理程序，在运行时通过调用open_softirq()注册软中断处理程序，两个参数 软中断的索引号和处理函数
	
tasklet:

		struct tasklet_struct
		{
		struct tasklet_struct *next;
		unsigned long state;			//保存tasklet状态， 判断当前tasklet是否已运行，对该tasklet进行加锁操作等
		atomic_t count;					// tasklet的开启与关闭  0：enable  1: disable
		void (*func)(unsigned long)；//该tasklet对应的回调处理函数，当我们使用tasklet该函数即需要我们自己定义，用于处理下半部
		unsigned long data;		//回调处理函数的传参
		};


	tasklet是利用软中断实现的一种下半部机制，它和进程没有任何关系
	void tasklet_init(struct tasklet_struct *t,  
 void (*func)(unsigned long), unsigned long data);  
	  
	#define DECLARE_TASKLET(name, func, data) \  
		struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }  
	#define DECLARE_TASKLET_DISABLED(name, func, data) \  
		struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }  
	  
	void tasklet_disable(struct tasklet_struct *t);   
	/*函数暂时禁止给定的tasklet被tasklet_schedule调度，直到这个tasklet被再次被enable；若这个tasklet当前在运行, 这个函数忙等待直到这个tasklet退出*/  
	  
	void tasklet_disable_nosync(struct tasklet_struct *t);   
	/*和tasklet_disable类似，但是tasklet可能仍然运行在另一个 CPU */  
	  
	void tasklet_enable(struct tasklet_struct *t);   
	/*使能一个之前被disable的tasklet；若这个tasklet已经被调度, 它会很快运行。tasklet_enable和tasklet_disable必须匹配调用, 因为内核跟踪每个tasklet的"禁止次数"*/   
	  
	void tasklet_schedule(struct tasklet_struct *t);   
	/*调度 tasklet 执行，如果tasklet在运行中被调度, 它在完成后会再次运行; 这保证了在其他事件被处理当中发生的事件受到应有的注意. 这个做法也允许一个 tasklet 重新调度它自己*/  
	  
	void tasklet_hi_schedule(struct tasklet_struct *t);   
	/*和tasklet_schedule类似，只是在更高优先级执行。当软中断处理运行时, 它处理高优先级 tasklet 在其他软中断之前，只有具有低响应周期要求的驱动才应使用这个函数, 可避免其他软件中断处理引入的附加周期*/  
  
	void tasklet_kill(struct tasklet_struct *t);   
	/*确保了 tasklet 不会被再次调度来运行，通常当一个设备正被关闭或者模块卸载时被调用。如果 tasklet 正在运行, 这个函数等待直到它执行完毕。若 tasklet 重新调度它自己，则必须阻止在调用 tasklet_kill 前它重新调度它自己，如同使用 del_timer_sync*/  
	
	static inline void tasklet_schedule(struct tasklet_struct *t)  
{  
        /*如果需要调度的tasklet的state不为TASKLET_STATE_SCHED，则触发之。这样，就保证了多个cpu不可能同时运行同一个tasklet，因为如果一个tasklet被调度过一次，那么它的state字段就会被设置TASKLET_STATE_SCHED标记，然后插入per-cpu变量的链表中。如果这时另外一个cpu也去调度该tasklet，那么就会在下面的if语句中被挡掉，不会运行到__tasklet_schedule()，从而不会插入到另外这个cpu的per-cpu变量的链表中，就不会被运行到。所以这里是保证了tasklet编写的函数不用是可重入的，这样就方便了编程人员。(注意，softirq机制需要编写可重入的函数)*/  
       if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))  
              __tasklet_schedule(t);  
}  

使用tasklet
	1.
	如果你准备间接引用则动态的创建tasklet,
	如果直接引用则静态的创建
	
	DECLARE_TASKLET(name , func , data)
	DECLARE_TASKLET_DISABLED(name , func , data)
	两个宏都能根据给定的名称静态地创建一个task_struct结构，当该tasklet被调度之后
	给定的func会被执行，它的参数由data给出，这两个宏之间的区别在于引用计数器的初始值设置不同
	前一个宏把创建的tasklet的引用计数器设置为0 ，该tasklet处于激活状态，另一个把引用计数器设置为1 ，所以该tasklet处于禁止状态
		例如：
			DECLARE_TASKLET(my_tasklet , my_tasklet_handler ， dev);
			等价于：
			struct tasklet_struct my_tasklet = { NULL , 0 , ATOMIC_INIT(0) , my_tasklet_handler , dev}
						对应于	tasklet_struct *next ， tasklet状态state , 锁计数器count , 处理函数func , func需要的参数
	
	还可以通过一个间接引用（指针）赋给一个动态创建的tasklet_struct 结构的方式来初始化一个tasklet_init()
		tasklet_init(t , tasklet_handler , dev)
		
	2.
	编写处理程序
		void tasklet_handler(usngined long data)
		因为是靠软中断实现，所以taskled不能睡眠，因此不能再tasklet中使用信号量或者其他什么阻塞式的函数，
		由于tasklet运行时允许响应中断，所以你必须做好预防工作，如果你的tasklet和其他的tasklet或者软中断共享了数据，
		必须适当的锁保护
		
	3.
	调度tasklet
	通过调用tasklet_schedule()函数并传递给它相应的tasklet_struct指针，该taskled就会被调度以便执行
		tasklet_schedule(&my_tasklet)；
		在tasklet被调度之后，只要有机会它就会尽可能早地运行，在它还没有得到运行机会之前，如果有一个相同的tasklet又被调度了
		那么它任然只会运行一次，而如果这时它已经开始运行了，比如说在另一个处理器上，那么这个新的tasklet会被重新调度并再次运行
		禁止某个tasklet
		tasklet_disable(&tasklet)
		如果该tasklet当前正在执行，这个函数会等到它执行完毕再返回，也可以用 tasklet_disable_nosync() 函数，
		可以用tasklet_kill()函数从挂起的队列中去掉一个tasklet，该函数的参数是一个指向某个tasklet的tasklet_struct的长指针，
		这个函数首先等待该tasklet执行完毕，然后再将它移去，
		
	ksoftirqd  辅助处理软中断的内核线程
	

工作队列：
	工作队列是另外一种推后执行的形式，交由一个内核线程去执行
	
	使用工作队列：
		1.创建推后的工作
			可以通过DECLARE_WORK在编译时静态创建该结构体
			DECLARE_WORK(name , void (*func) (void *) , void *data);
			这样就会静态创建一个名为name，处理函数为func，参数为data的work_struct结构体
			也可以在运行时通过指针创建一个工作：
			INIT_WORK(struct work_struct *work , void(*func)(void *) , void *data);
		2.工作队列处理函数：
			void work_handler(void * data)
			这个函数会由一个工作者线程执行，因此，函数会运行在进程上下文中，默认情况下，允许响应中断，并且不持有任何锁
		3.对工作进行调度
			想要把给定工作的处理函数提交给缺省的events工作线程，只需调用
				schedule_work(&work);
			work马上就会被调度，一旦其所在的处理器上的工作者线程被唤醒，它就会被执行
			有时候不需要马上执行而是延迟一段时间，则可以使用：
				schedule_delayed_work(&work , delay)
				delay指定 等待的时钟节拍数
		4.刷新操作：
			排入队列的工作会在工作者线程下一次被唤醒的时候执行，
			刷新指定工作队列的函数：
				void flush_scheduled_work(void)
				函数会一直等待，直到队列中所有对象都被执行以后才返回。在等待所有待处理的工作执行的时候，该函数会进入休眠状态，所以只能在进程上下文中使用它。
				但这个函数不会取消任何延迟执行的工作，任何通过 schedule_delayed_work()调度的工作，如果其延迟时间未结束，
				它并不会因为调用flush_scheduled_work() 而被刷新掉，因此需要取消延迟执行的工作：
					int cancel_delayed_work(struct work_struct *work);
		5.创建新的工作队列
			struct workqueue_struct *create_workqueue(const char * name);
			name 参数用于该内核线程的命名，比如缺省的events队列的创建就调用
				struct workqueue_struct * keventd_wq;
				keventd_wq = create_workqueue("events");
				这样就会创建所有的工作者线程（系统中的每个处理器都有一个）
			创建一个工作的时候无需考虑工作队列的类型
	
通常在工作队列和软中断/tasklet中作出选择非常容易，如果推后执行的任务需要睡眠，那么就选择工作队列，如果推后执行的任务不需要睡眠，那么就选择软中断或者tasklet
		
		进程就是出于执行期的程序，但进程并不仅仅局限于一段可执行代码，通常进程还要包含其他资源，
像打开的文件，挂起的信号，内核内部数据，处理器状态。当然还包括用来存放全局变量的数据段

	执行线程，简称线程（thread），是在进程中活动的对象，每个线程都拥有一个独立的程序计数器、进程栈和一组进程
寄存器，内核调度的对象是线程，而不是进程。
	现在的系统中，包含了多个线程的多线程程序司空见惯
	对Linux而言，线程只不过是一种特殊的进程罢了
	
	虚拟处理器和虚拟内存给进程一种假象，让这些进程觉得自己独享整个处理器或者整个内存
	
	调用fork()的进程称为父进程，在调用结束返回的这个位置开始，父进程继续执行，新的子进程开始执行，
	fork()系统调用从内核返回两次，一次回到父进程，另一次回到新产生的子进程
	
	最终程序通过exit()系统调用退出执行，这个函数会终结进程并且将其占用的资源释放掉
	父进程可以通过wait4()系统调用查询子进程是否终结
	
	内核把进程的列表存放在叫做 任务队列（task list）的双向循环链表中，链表中的每一项都是类型为task_struct
	称为进程描述符的街头，定义在<linux/sched.h>文件中
	进程描述附中包含的数据能完整的描述一个正在执行的程序：它打开的文件，进程的地址空间，挂起的信号
	进程的状态
	
	内核通过一个唯一的进程标识值（process idenification value）PID 来标识每个进程，PID是一个数，表示为
	pid_t隐含类型，实际上就是一个Int类型，为了兼容PID最大值默认为32768，
	但是这个值对大型服务器来说还不够用，这个值越小，转一圈就越快，本来数值大的进程比数值小的进程迟运行
	但这样一来就破坏了这一原则，如果需要修改 位置在 /proc/sys/kernel/pid_max
	
	内核中访问任务同城需要获得指向其task_struct的指针，实际上，内核中大部分处理进程的代码都是直接通过
	task_struct进行的
	
	进程描述符中的state域描述了进程的当前状态，系统中的每个进程都必然处于五种进程状态中的一种
		TASK_RUNNING(运行)-----进程是可执行的，它或者正在执行，或者在运行队列中等待执行
		TASK_INTERRUPTIBLE（可中断）-----进程正在睡眠，也就是说它被阻塞。
		TASK_UNINTERRUPTIBLE（不可中断）
		__TASK_TRACED-----被其他进程跟踪的进程
		__TASK_STOPPED(停止)
		
	内核经常需要调整 某个进程的状态，这时最好使用set_tesk_state（task,state）函数
	
进程家族树
	在Linux系统中，所有的进程都是PID为1的init进程的后代，内核在系统启动的最后阶段启动init进程
	改进成都去系统的初始化脚本（initscript）并执行其他的相关程序，最终完成系统启动的整个过程
	
	系统中的每个进程必有一个父进程
	进程间的关系放在进程描述符中，每个task_struct都包含一个指向其父进程task_struct叫做parent的指针，
	还包含一个称谓children的子进程链表
	
进程创建：
	首先在新的地址空间里创建进程，读入可执行文件，最后开始执行
	分为两个单独的函数执行： fork() 和  exec()
	fork()通过拷贝当前进程创建一个子进程，子进程与父进程的区别仅仅在于PID，PPID（父进程的进程号，子进程
	将其设置为被拷贝进程的PID）和某些资源和统计量
	exec()函数负责读取可执行文件并将其载入地址空间开始运行